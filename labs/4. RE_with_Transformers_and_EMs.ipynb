{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. RE_with_Transformers_and_EMs.ipynb","provenance":[],"mount_file_id":"1GWcFdlcDXmiHv83Fog109JKuWD--wBC-","authorship_tag":"ABX9TyM5IMfwZy3xWE+vbncvSv0T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GIsfM2pyh7kt"},"source":["# Relation extraction with Entity Markers\n","\n","We will learn how to implement a relation extractor using [ROBERTA](https://arxiv.org/abs/1907.11692) archicture and Entity Marker context represenation proposed by [Soares et al. 2019](https://www.aclweb.org/anthology/P19-1279.pdf). We will use ACE-2005 dataset to train and evaluate our model. As you will notice you will need to understand a code with some level of complexity, in which we extend a transformer based encoder to use it in a relatin extraction task. \n","\n","You don't need to code anything in this notebook, but it is worth to spend some time understanding the modules that we use in this notebook (`ACERelationClassificationDataset` and `RobertaForTupleClassification`).\n","\n","Goal of this lab are 1) to earn to modify the tokenizer to include special tokens (entity markers in this case), 2) to learn to extend neural archicteture on top of pretrained models provided in Huggingface, and 3) review advanced concepts of deep learning and relation extraction. \n","    "]},{"cell_type":"code","metadata":{"id":"EjNsJZCHiZqW"},"source":["# Mount Drive files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gg-iSY76m-2y"},"source":["## Set up\n","\n","We first need to install transformers modules from Huggingface. This is done directly using pip. After the instalation of the transformers modules, we have to set up the enviroment to use our custom implementation of the entity markers, which is build on top of the transformers. If you want to inspect the code, these are the most relevant parts you need to understand: \n","\n","- Module for manage datasets: __dataset.py__\n","  + We will make use of `ACERelationClassificationDataset` class, which read data from preprocesed JSON file.\n","- Implemetation of the model: __models.py__\n","   + We will use  `RobertaForTupleClassification` for relation extraction with entity markers.\n","\n","The code for training and testing are implemented in the notebook."]},{"cell_type":"code","metadata":{"id":"Cm6gg4-_jc8B"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eq1ktRuvjRtQ"},"source":["In order to make all the imports correctly, we need to add the path that includes the modules for entity markers based relation extraction. Make sure you have all the modules in your Drive. Check your path to the Python modules included in `entity_markers` is correct. "]},{"cell_type":"code","metadata":{"id":"pQLcpe-Uhrrt"},"source":["import sys\n","em_dir = 'drive/MyDrive/Colab Notebooks/nlp-app-II/labs/entity_marker'\n","sys.path.append(em_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdWhRMe0jDkn"},"source":["import torch\n","from torch.utils.data import DataLoader\n","import argparse\n","import json\n","import os\n","\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","from transformers import (\n","    AutoConfig,\n","    AutoTokenizer,\n","    set_seed,\n","    AdamW,\n","    get_linear_schedule_with_warmup\n",")\n","\n","from models import RobertaForTupleClassification\n","from dataset import ACERelationClassificationDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KJj_mUDlBrg"},"source":["def load_defaults(opt: argparse.Namespace) -> argparse.Namespace:\n","    # Model arguments\n","    opt.model_name_or_path = getattr(opt, 'model_name_or_path', 'xlm-roberta-base')\n","    opt.use_fast = getattr(opt, 'use_fast', False)\n","    opt.fp16 = getattr(opt, 'fp16', False) if hasattr(torch.cuda, 'amp') else False\n","\n","    # Training arguments\n","    opt.seed = getattr(opt, 'seed', 0)\n","    opt.cache_dir = getattr(opt, 'cache_dir', None)\n","    opt.save_dir = getattr(opt, 'save_dir', 'output/')\n","    opt.batch_size = getattr(opt, 'batch_size', 16)\n","    opt.do_eval = getattr(opt, 'do_eval', False)\n","    opt.do_test = getattr(opt, 'do_test', False)\n","    opt.learning_rate = getattr(opt, 'learning_rate', 5e-5)\n","    opt.epochs = getattr(opt, 'epochs', 3)\n","    opt.gradient_accumulation_steps = getattr(opt, 'gradient_accumulation_steps', 1)\n","    opt.num_warmup_steps = getattr(opt, 'num_warmup_steps', 0)\n","    opt.max_grad_norm = getattr(opt, 'max_grad_norm', 5.0)\n","\n","    # Data arguments\n","    opt.negative_class = getattr(opt, 'negative_class', False)\n","    opt.add_trigger_info = getattr(opt, 'add_trigger_info', False)\n","    opt.add_clean_context = getattr(opt, 'add_clean_context', False)\n","\n","    return opt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0j-bZFT6lOyS"},"source":["We need to load a configuration file where we indicate the main stuff to train and evaluate the model (data paths, hyperparameters, etc). Open the config file from the notebook so you can edit directly."]},{"cell_type":"code","metadata":{"id":"C-CmG8JUlPg5"},"source":["config_file = em_dir + \"/config_re.json\"\n","with open(config_file) as f:\n","    opt = json.load(f)\n","    opt = argparse.Namespace(**opt)\n","opt = load_defaults(opt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WvtrLVLymESx"},"source":["## Prepare logs, load tokenizers and the pretrained model\n","In this section will load the pretrained model and prepare the tokenizer to include the entity markers as special tokens. We want to have some special tokens in which the tokenizer does not divide them in subwords, and also we want those tokens to encode the contextual representation of the entity pairs that exibit a relation type (in a similar way as we do with [CLS] and [SEP])\n","\n"]},{"cell_type":"code","metadata":{"id":"1T22gnhylOhl"},"source":["# Log\n","train_log = vars(opt).copy()\n","train_log['epochs'] = []\n","\n","# Set the seed\n","set_seed(opt.seed)\n","\n","# Make the output dir if not exists\n","os.makedirs(opt.save_dir, exist_ok=True)\n","\n","# Load the configuration\n","num_labels = len(ACERelationClassificationDataset.label2id)\n","label2id = ACERelationClassificationDataset.label2id\n","id2label = {int(value): key for key, value in label2id.items()}\n","\n","config = AutoConfig.from_pretrained(\n","    opt.model_name_or_path,\n","    num_labels=num_labels,\n","    id2label=id2label,\n","    label2id=label2id,\n","    cache_dir=opt.cache_dir\n",")\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\n","    opt.model_name_or_path,\n","    cache_dir=opt.cache_dir,\n","    use_fast=opt.use_fast\n",")\n","# Include entity markers as tokens in the tokenizer\n","new_tokens = ['<e1s>', '<e1e>', '<e2s>', '<e2e>']\n","tokenizer.add_tokens(new_tokens)\n","tokenizer.save_pretrained(opt.save_dir)\n","\n","# Update the config with new information\n","config.first_marker_token_id = tokenizer.convert_tokens_to_ids(['<e1s>', '<e1e>'])\n","config.second_marker_token_id = tokenizer.convert_tokens_to_ids( ['<e2s>', '<e2e>'])\n","\n","# Load the model\n","model = RobertaForTupleClassification.from_pretrained(\n","    opt.model_name_or_path,\n","    config=config,\n","    cache_dir=opt.cache_dir\n",")\n","\n","# Resize the vocab\n","config.vocab_size = len(tokenizer)\n","model.resize_token_embeddings(config.vocab_size)\n","\n","model.save_pretrained(opt.save_dir)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0Eq_WUNrRNH"},"source":["### Exercise 1 \n","- Inspect the code and indicate the lines where we update the tokenizer with entity markers.\n","\n","### Exercise 2\n","\n","- Inspect the code for the class `RobertaForTupleClassificication` in `models.py`. Can you identify the how entity-markers approach is implemented? "]},{"cell_type":"markdown","metadata":{"id":"P2S6Ft13mtWa"},"source":["## Load ACE data for RE"]},{"cell_type":"code","metadata":{"id":"LolXf0O0mxOX"},"source":["# Load the data\n","train_dataset = ACERelationClassificationDataset(\n","    file_path=opt.train_data,\n","    tokenizer=tokenizer,\n","    from_preprocessed=True\n",")\n","\n","train_dataloader = DataLoader(\n","    train_dataset, collate_fn=train_dataset.collate_fn,\n","    batch_size=opt.batch_size, shuffle=True\n",")\n","\n","eval_dataset = ACERelationClassificationDataset(\n","    file_path=opt.eval_data,\n","    tokenizer=tokenizer,\n","    from_preprocessed=True\n",")\n","\n","eval_dataloader = DataLoader(\n","    eval_dataset, collate_fn=eval_dataset.collate_fn,\n","    batch_size=opt.batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fr8TrpNotI6z"},"source":["### Exercise 3\n","Inspect the training data. Can you see the entity markers? "]},{"cell_type":"code","metadata":{"id":"02BL9w8zrcuH"},"source":["train_dataset[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6bhDEnHktdsq"},"source":["## Prepare the training"]},{"cell_type":"code","metadata":{"id":"Tu1EAk24tev-"},"source":["no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": getattr(opt, 'weight_decay', 0.01)\n","    },\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(\n","    optimizer_grouped_parameters,\n","    lr=opt.learning_rate\n",")\n","\n","num_training_steps = len(train_dataset) * opt.epochs // (opt.batch_size * opt.gradient_accumulation_steps)\n","lr_scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=opt.num_warmup_steps,\n","    num_training_steps=num_training_steps\n",")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.to(device)\n","\n","if opt.fp16:\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","# Training loop\n","print(\"***** Running training *****\")\n","print(f\"  FP16 enabled: {opt.fp16}\")\n","print(f\"  Num examples = {len(train_dataset)}\")\n","print(f\"  Num Epochs = {opt.epochs}\")\n","print(f\"  Train batch size = {opt.batch_size}\")\n","print(f\"  Gradient Accumulation steps = {opt.gradient_accumulation_steps}\")\n","print(f\"  Total optimization steps = {num_training_steps}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PMkfwUMusOA"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"gSy80kmRuvOf"},"source":["    best_eval_score = 0.0\n","        \n","    for epoch in range(getattr(opt, 'epochs', 3)):\n","        # Prepare the model for epoch\n","        model.zero_grad()\n","        model.train()\n","\n","        train_log['epochs'].append({})\n","\n","        step, tp, p, r, total, total_loss = 0, 0, 0, 0, 0, 0\n","        progress = tqdm(train_dataloader, total=(len(train_dataset)//opt.batch_size),\n","                        desc=f\"Epoch: {epoch} - Loss: {total_loss}\"\n","        )\n","        for batch, _ in progress:\n","            # Batch to cuda\n","            batch = {key: value.to(device) for key, value in batch.items()}\n","\n","            # Forward pass\n","            if opt.fp16:\n","                with torch.cuda.amp.autocast():\n","                    loss, output = model(**batch)\n","            else:\n","                loss, output = model(**batch)\n","            \n","            total_loss += loss.item()\n","            loss = loss / opt.gradient_accumulation_steps \n","\n","            # Backward pass\n","            if opt.fp16:\n","                scaler.scale(loss).backward()\n","            else:\n","                loss.backward()\n","            \n","            if (step + 1) % opt.gradient_accumulation_steps == 0:\n","                if opt.fp16:\n","                    scaler.unscale_(optimizer)\n","                    \n","                torch.nn.utils.clip_grad_norm_(\n","                    model.parameters(), opt.max_grad_norm\n","                )\n","\n","                if opt.fp16:\n","                    scaler.step(optimizer)\n","                    scaler.update()\n","                else:\n","                    optimizer.step()\n","\n","                lr_scheduler.step()\n","                model.zero_grad()\n","\n","            # Evaluation \n","            pred = output.detach().argmax(-1)\n","            true = batch['labels'].detach()\n","            p += (pred != 0).sum().item()\n","            r += (true != 0).sum().item()\n","            tp += ((pred == true).float() @ (true != 0).float()).item()\n","\n","            precision = tp*100/p if p > 0.0 else 0.0\n","            recall = tp*100/r if r > 0.0 else 0.0\n","            f1_score = (2*precision*recall) / (precision+recall) if precision+recall else 0.0\n","            progress.set_description(f\"Epoch: {epoch} - Loss: {total_loss/(step+1):.3f} - P/R/F: {precision:.2f}/{recall:.2f}/{f1_score:.2f}\")\n","            \n","            step += 1\n","            \n","        print(f\"Training evaluation results:\")\n","        precision = tp*100/p if p > 0.0 else 0.0\n","        recall = tp*100/r if r > 0.0 else 0.0\n","        f1_score = (2*precision*recall) / (precision+recall) if precision+recall else 0.0\n","        print(f\"Precision/Recall/F-Score: {precision:.2f}/{recall:.2f}/{f1_score:.2f}\")\n","        train_log['epochs'][-1][\"train\"] = {\n","            'loss': total_loss/(step+1),\n","            'precision': precision,\n","            'recall': recall,\n","            'f1-score': f1_score\n","        }\n","\n","        # Evaluation loop\n","        model.eval()\n","        if opt.do_eval:\n","            step, tp, p, r, total, total_loss = 0, 0, 0, 0, 0, 0\n","            \n","            progress = tqdm(eval_dataloader, total=(len(eval_dataset)//opt.batch_size),\n","                            desc=f\"Epoch: {epoch} - Loss: {total_loss}\"\n","            )\n","            for batch, _ in progress:\n","                batch = {key: value.to(device) for key, value in batch.items()}\n","                \n","                # Forward pass\n","                with torch.no_grad():\n","                    if opt.fp16:\n","                        with torch.cuda.amp.autocast():\n","                            loss, output = model(**batch)\n","                    else:\n","                        loss, output = model(**batch)\n","                \n","                total_loss += loss.item()\n","                # Evaluation \n","                pred = output.detach().argmax(-1)\n","                true = batch['labels'].detach()\n","                p += (pred != 0).sum().item()\n","                r += (true != 0).sum().item()\n","                tp += ((pred == true).float() @ (true != 0).float()).item()\n","\n","                precision = tp*100/p if p > 0.0 else 0.0\n","                recall = tp*100/r if r > 0.0 else 0.0\n","                f1_score = (2*precision*recall) / (precision+recall) if precision+recall else 0.0\n","                progress.set_description(f\"Epoch: {epoch} - Loss: {total_loss/(step+1):.3f} - P/R/F: {precision:.2f}/{recall:.2f}/{f1_score:.2f}\")\n","                \n","                step += 1\n","\n","            print(f\"Development evaluation results:\")\n","            precision = tp*100/p if p > 0.0 else 0.0\n","            recall = tp*100/r if r > 0.0 else 0.0\n","            f1_score = (2*precision*recall) / (precision+recall) if precision+recall else 0.0\n","            print(f\"Precision/Recall/F-Score: {precision:.2f}/{recall:.2f}/{f1_score:.2f}\")\n","            train_log['epochs'][-1][\"dev\"] = {\n","                'loss': total_loss/(step+1),\n","                'precision': precision,\n","                'recall': recall,\n","                'f1-score': f1_score\n","            }\n","            eval_score = f1_score\n","\n","            if eval_score > best_eval_score:\n","                print(\"Saving best model...\")\n","                model.save_pretrained(opt.save_dir)\n","                best_eval_score = eval_score\n","\n","        else:\n","            model.save_pretrained(opt.save_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDJHm7eu5P-a"},"source":["with open(os.path.join(opt.save_dir, 'train_log.json'), 'wt') as f:\n","    json.dump(train_log, f)\n","print(\"Train log saved in: {}\".format(os.path.join(opt.save_dir, 'train_log.json')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XGgB6E0-Ce4"},"source":["Following code obtains the predictions, print them and plots confusion matrix.\n"]},{"cell_type":"code","metadata":{"id":"AREhrFiyAFhQ"},"source":["predictions = []\n","info = []\n","eval_dataloader = DataLoader(\n","    eval_dataset, collate_fn=eval_dataset.collate_fn,\n","    batch_size=1\n",")\n","with torch.no_grad():\n","    for batch, inst_info in eval_dataloader:\n","        batch = {key: value.to(device) for key, value in batch.items()}\n","        if opt.fp16:\n","            with torch.cuda.amp.autocast():\n","                loss, output = model(**batch)\n","        else:\n","            loss, output = model(**batch)\n","\n","        output = output.argmax(dim=-1).detach().cpu().tolist()\n","        info.append(inst_info)\n","        predictions.extend(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXKwMoIJdV6A"},"source":["def remove_markers(marked_tokens):\n","    return [token for token in marked_tokens if token not in [\"<e1s>\", \"<e1e>\", \"<e2s>\", \"<e2e>\"]]\n","\n","for i, prediction in enumerate(predictions):\n","    predicted_label = id2label[prediction]\n","    gold_label = eval_dataset[i]['label']\n","    sentence =  \" \".join(eval_dataset[i]['tokens'])\n","    print(\"{} - {}: {}\".format(predicted_label, gold_label, sentence))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iCj8qYRDXyT"},"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","gold = [eval_dataset[i]['label'] for i in range(len(eval_dataset))]\n","pred = [id2label[prediction] for prediction in predictions]\n","cm = confusion_matrix(gold, pred, labels=list(label2id.keys()))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label2id.keys()))\n","\n","disp.plot(xticks_rotation='vertical')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zueDF1ffQziW"},"source":["### Exercise 4: \n","- Where is located the confusion?"]}]}