{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2. NER_with_spacy.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOqPJkkQN0xBvuw661Igpxj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cmqC0llnDL0C"},"source":["# Training and Evaluating an NER model with spaCy on the CoNLL dataset\n","\n","In this notebook, we will take a look at using spaCy commandline to train and evaluate a NER model. We will also compare it with the pretrained NER model in spacy. \n","\n","Note: we will create multiple folders during this experiment:\n","`spacyNER_data `"]},{"cell_type":"code","metadata":{"id":"CU0jQOsd98mn"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kEci82ZAYt__"},"source":["## spaCy v3.0\n","\n","We will install the last version of SpaCy (v3.0) as it provides better training worklflow and config system to train custom models. In addition, it features transformer-based pipelines that bring spaCyâ€™s accuracy right up to the current state-of-the-art.\n","\n","In this tutorial we will learn how to use command line interface (CLI) along with the config file to train NER model in CONLL-2003 dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"ScO_pnurTmwR"},"source":["!pip install -U spacy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDc_hWChikYZ"},"source":["Check you are using the correct spaCy version."]},{"cell_type":"code","metadata":{"id":"Fd9nbTsDT5OA"},"source":["import spacy\n","print(spacy.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unGZ25YYYoeE"},"source":["## Step 1: Converting data to binary files so it can be used by Spacy\n","\n","Convert data from conll to spaCy format. Command provides more than one converter (IOB, BLIOU, etc). See converter's detail in https://spacy.io/api/cli#convert "]},{"cell_type":"code","metadata":{"id":"QQv3vzxD-FSu"},"source":["data_dir=\"drive/MyDrive/Colab Notebooks/nlp-app-II/data\"\n","#Read the CONLL data from conll2003 folder, and store the formatted data into a folder spacyNER_data\n","!mkdir spacyNER_data\n","#the above two lines create folders if they don't exist. If they do, the output shows a message that it\n","#already exists and cannot be created again\n","!python3 -m spacy convert \"drive/MyDrive/Colab Notebooks/nlp-app-II/data/conll2003/en/train.txt\" spacyNER_data -c ner\n","!python3 -m spacy convert \"drive/MyDrive/Colab Notebooks/nlp-app-II/data/conll2003/en/test.txt\" spacyNER_data -c ner\n","!python3 -m spacy convert \"drive/MyDrive/Colab Notebooks/nlp-app-II/data/conll2003/en/valid.txt\" spacyNER_data -c ner"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZ7kNZukY1VB"},"source":["## Step 2: Create config file for spaCy\n","\n","In this step we are going to create the config file that will be used by spaCy.\n","To get started with the recommended settings for your use case, check out the [quickstart widget](https://spacy.io/usage/training#quickstart) or run the [init config](https://spacy.io/api/cli#init-config) command. \n"]},{"cell_type":"markdown","metadata":{"id":"XdKrESFmpAwK"},"source":["### Exercise 1: \n","1. Create basic config file with the quickstart widget. \n","2. Upload to your drive in the `data` folder. \n","3. Modify your basic config if you need. For example, training for 3500 steps is enough. \n","4. Create final config file (`config.cfg`) with `init fill-config` command (see the code below)\n","\n"]},{"cell_type":"code","metadata":{"id":"lh0LiDchYzfG"},"source":["base_config_path=data_dir+\"/base_config.cfg\"\n","!cp \"drive/MyDrive/Colab Notebooks/nlp-app-II/data/base_config.cfg\" \"base_config.cfg\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GM1sDUOSdaVF"},"source":["!python -m spacy init fill-config base_config.cfg config.cfg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eM3i6EttrK8U"},"source":["## Step:3 Training the NER model with Spacy (CLI)\n","\n","All the commandline options can be seen at: https://spacy.io/api/cli#train\n","We are training using the train program in spacy, for English (en), and the results are stored in a folder \n","called \"model\" (created while training). Our training file is in \"spacyNER_data/train.spacy\" and the validation file is at: \"spacyNER_data/valid.spacy\". \n","\n"]},{"cell_type":"code","metadata":{"id":"BZOspfDH-YUP"},"source":["!python -m spacy train config.cfg --output ./model --paths.train spacyNER_data/train.spacy --paths.dev spacyNER_data/valid.spacy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GO0BDFZqrHm_"},"source":["Notice how the performance improves with each iteration!\n"]},{"cell_type":"markdown","metadata":{"id":"hc5YA8xcroYq"},"source":["## Step4: Evaluating the model with test data set"]},{"cell_type":"code","metadata":{"id":"3ONoFGcvGUP5"},"source":["#create a folder to store the output and visualizations. \n","!mkdir result\n","!python3 -m spacy evaluate model/model-best spacyNER_data/test.spacy -o results -dp result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Rl0DtEHyLpS"},"source":["# save model for later\n","!cp -r /content/model \"drive/MyDrive/Colab Notebooks/nlp-app-II/data/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Feri8GnZpgOD"},"source":["### Exercise 2:\n","- Explore different options of training configuration. You can take advantage of the GPUs provided by Google Colab and train a transformer-based model.  See https://spacy.io/usage/training#quickstart"]},{"cell_type":"markdown","metadata":{"id":"xkMjWlsb--mw"},"source":["## Load your own model to use in Python code"]},{"cell_type":"code","metadata":{"id":"PmteShuiCxxE"},"source":["import spacy\n","nlp = spacy.load(\"model/model-best\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Su4HHolwXk2K"},"source":["nlp.pipe_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ki7u9NZWC8GS"},"source":["text = \"Japan began the defence of their Asian Cup title.\"\n","doc = nlp(text)\n","\n","print(doc.text)\n","for entity in doc.ents:\n","    print(entity.text, entity.label_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QMaXd1ZH_YmC"},"source":["## Compare with the pretrained model\n","\n","As you know spaCy provides various pipelines models. One of the most used is the `en_core_web_sm` model, which also provides NER module in its pipeline. \n"]},{"cell_type":"markdown","metadata":{"id":"RwWf1RsyrAvr"},"source":["### Exercise 3\n","\n"," 1. Download and load `en_core_web_sm` into your code\n"," 2. Process some texts with the model\n"," 3. What's the difference with your custom models and the pretrained one?"]},{"cell_type":"code","metadata":{"id":"wuWxfeL2-LxG"},"source":["!python -m spacy download en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhY0FMTv78M0"},"source":["nlp_pre = spacy.load(\"en_core_web_sm\")\n","doc = nlp_pre(text)\n","\n","for entity in doc.ents:\n","    print(entity.text, entity.label_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7Q2ymjmR3LS"},"source":["!python -m spacy download en_core_web_sm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ube9XBIQH43o"},"source":["## Visualization\n","\n","\n","info: https://spacy.io/usage/visualizers"]},{"cell_type":"code","metadata":{"id":"nz--HEOaIAj4"},"source":["from IPython.core.display import display, HTML\n","from spacy.training import Corpus\n","from spacy import displacy\n","\n","reader = Corpus('spacyNER_data/test.spacy')\n","test_data = reader(nlp)\n","test_golds = [example for example in test_data]\n","test_texts = [example.text for example in test_golds]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYkVyko-mqqn"},"source":["sent_i = 40\n","test_gold = test_golds[sent_i]\n","test_text =test_texts[sent_i]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVi3_-V9nSM_"},"source":["Show gold annotations"]},{"cell_type":"code","metadata":{"id":"9s10t4oDaEk3"},"source":["entities = [(i, ent) for i, ent in enumerate(test_gold.to_dict()['doc_annotation']['entities']) if ent != \"O\"]\n","tokens = test_gold.to_dict()['token_annotation']['ORTH']\n","ents = []\n","for i, label in entities:\n","    prefix, label = label.split('-')\n","    start = len(' '.join(tokens[0:i]))\n","    end = len(' '.join(tokens[0:(i+1)]))\n","    if prefix == 'I' or prefix == 'L':\n","        ents[-1]['end'] = end\n","    if prefix == 'B' or prefix == 'U':   \n","       ents.append({'start':start, 'end':end, 'label': label})\n","    #print('start:{} -  end:{} - {}-{}'.format(start, end, prefix, label))\n","\n","ex = [{'text':  ' '.join(tokens), 'ents': ents, 'title': None}]\n","html = displacy.render(ex, style=\"ent\", manual=True)\n","display(HTML(html))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8BVT09O9nZ4q"},"source":["Show your model's predictions"]},{"cell_type":"code","metadata":{"id":"CBwGzU5gOH_H"},"source":["doc = nlp(test_text)\n","html = displacy.render(doc, style=\"ent\", jupyter=True)\n","display(HTML(html))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRaD2NsingRq"},"source":["Show pretrained model's predictions"]},{"cell_type":"code","metadata":{"id":"nfASt1c1SY_E"},"source":["doc = nlp_pre(test_text)\n","html = displacy.render(doc, style=\"ent\", jupyter=True)\n","display(HTML(html))"],"execution_count":null,"outputs":[]}]}